"""
ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ ì„¤ì •(ì›ë³¸/ì „í†µ/ìƒì„±í˜•)ì„ ê°™ì€ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ê³µì • ë¹„êµ
"""

from pathlib import Path
import json
import torch

from data_preparation import create_few_shot_cifar10, build_cifar10_with_sd
from augmentation import create_augmented_dataset, AugmentedDataset
from models_custom import get_resnet18_cifar10
from train import train_classifier


def run_experiment(
    experiment_name: str,
    samples_per_class: int = 100,
    num_augment: int = 0,          # ì „í†µì  ì¦ê°• ë°°ìˆ˜(0ì´ë©´ ë¯¸ì‚¬ìš©)
    epochs: int = 100,
    batch_size: int = 128,
    lr: float = 0.05,
    use_generated: bool = False,   # ìƒì„±í˜•(sd32) í¬í•¨ ì—¬ë¶€
) -> dict:
    """
    ì‹¤í—˜ ì‹¤í–‰

    Args:
        experiment_name: ì‹¤í—˜ ì´ë¦„ (ì˜ˆ: "baseline", "traditional", "generated")
        samples_per_class: í´ë˜ìŠ¤ë‹¹ ì›ë³¸ ì´ë¯¸ì§€ ê°œìˆ˜
        num_augment: ì „í†µì  ì¦ê°• ë°°ìˆ˜ (0=ì•ˆ í•¨, 1=1ë°°, 2=2ë°°...)
        epochs: í•™ìŠµ ì—í¬í¬
        batch_size: ë°°ì¹˜ í¬ê¸°
        lr: í•™ìŠµë¥ 
        use_generated: Stable Diffusion(sd32) ìƒì„± ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€

    Returns:
        result(dict): í•µì‹¬ ì§€í‘œ ë° ë©”íƒ€ ì •ë³´
    """
    print(f"\n{'='*70}")
    print(f"ì‹¤í—˜: {experiment_name}")
    print(f"{'='*70}")
    print("ì„¤ì •:")
    print(f"  - ì›ë³¸ ì´ë¯¸ì§€: {samples_per_class}ì¥/í´ë˜ìŠ¤ (ì´ {samples_per_class*10}ì¥)")
    print(f"  - ì „í†µì  ì¦ê°•: {num_augment}ë°°")
    print(f"  - ìƒì„± ì´ë¯¸ì§€(sd32): {'í¬í•¨' if use_generated else 'ë¯¸í¬í•¨'}")
    print(f"  - Epochs: {epochs} | Batch: {batch_size} | LR: {lr}")
    print(f"{'='*70}\n")

    # 1) ë””ë°”ì´ìŠ¤
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # 2) ë°ì´í„° ì¤€ë¹„ (ìƒì„±í˜• í¬í•¨/ë¯¸í¬í•¨ì— ë”°ë¼ ê³µì •í•œ ê²½ë¡œ ì„ íƒ)
    if use_generated:
        # âœ… í‘œì¤€ íŒŒì´í”„ë¼ì¸: ì›ë³¸ few-shot + sd32 ë³‘í•©, í…ŒìŠ¤íŠ¸ì…‹ë„ ë™ì¼ ê¸°ì¤€
        print("ğŸ“‚ ë°ì´í„° ì¤€ë¹„ ì¤‘... (ì›ë³¸ + ìƒì„±í˜• sd32 ë³‘í•©)")
        train_data = build_cifar10_with_sd(
            split="train",
            include_sd=True,
            samples_per_class=samples_per_class,
        )
        test_data = build_cifar10_with_sd(split="test")
        print("ğŸ¨ ìƒì„±í˜• ì´ë¯¸ì§€ í¬í•¨í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.")
    else:
        print("ğŸ“‚ ë°ì´í„° ì¤€ë¹„ ì¤‘... (ì›ë³¸/ì „í†µ)")
        train_original, test_data = create_few_shot_cifar10(samples_per_class=samples_per_class)
        if num_augment > 0:
            print(f"ğŸ”„ ì „í†µì  ì¦ê°• ì ìš©: {num_augment}ë°°")
            train_data = create_augmented_dataset(train_original, num_augment=num_augment)
        else:
            print("ğŸ“Œ ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš©")
            train_data = AugmentedDataset(train_original, augmentation=None, num_augment=0)

    print(f"\nìµœì¢… í›ˆë ¨ ë°ì´í„°: {len(train_data):,}ì¥")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data):,}ì¥\n")

    # 3) ëª¨ë¸
    print("ğŸ”§ ëª¨ë¸ ìƒì„±...")
    model = get_resnet18_cifar10()

    # 4) í•™ìŠµ
    save_dir = Path("./models")
    save_dir.mkdir(exist_ok=True)
    save_path = save_dir / f"{experiment_name}_best.pth"

    trained_model, history = train_classifier(
        model=model,
        train_dataset=train_data,
        test_dataset=test_data,
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        device=device,
        save_path=str(save_path),
    )

    # 5) ê²°ê³¼ ì €ì¥
    result = {
        "experiment_name": experiment_name,
        "samples_per_class": samples_per_class,
        "num_augment": num_augment,
        "use_generated": use_generated,
        "total_train_images": len(train_data),
        "epochs": epochs,
        "batch_size": batch_size,
        "lr": lr,
        "best_test_accuracy": history["best_acc"],
        "final_train_accuracy": history["train_acc"][-1],
        "final_test_accuracy": history["test_acc"][-1],
    }

    result_dir = Path("./results")
    result_dir.mkdir(exist_ok=True)
    with open(result_dir / f"{experiment_name}_result.json", "w") as f:
        json.dump(result, f, indent=2)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {result_dir / f'{experiment_name}_result.json'}")
    print(f"ğŸ’¾ ê°€ì¤‘ì¹˜ ì €ì¥: {save_path}")
    print(f"ğŸ¯ Best test accuracy: {history['best_acc']:.4f}")

    return result


# ==============================
# ë¯¸ë¦¬ ì •ì˜í•œ ì‹¤í—˜ ë‹¨ì¶• í•¨ìˆ˜ë“¤
# ==============================

def experiment_baseline(samples: int = 100, epochs: int = 100,
                        batch_size: int = 128, lr: float = 0.05) -> dict:
    """ì‹¤í—˜ 1: ì›ë³¸ë§Œ"""
    return run_experiment(
        experiment_name="baseline",
        samples_per_class=samples,
        num_augment=0,
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        use_generated=False,
    )


def experiment_traditional(samples: int = 100, augment_ratio: int = 1, epochs: int = 100,
                           batch_size: int = 128, lr: float = 0.05) -> dict:
    """ì‹¤í—˜ 2: ì›ë³¸ + ì „í†µì  ì¦ê°•"""
    return run_experiment(
        experiment_name="traditional",
        samples_per_class=samples,
        num_augment=augment_ratio,
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        use_generated=False,
    )


def experiment_generated(samples: int = 100, epochs: int = 100,
                         batch_size: int = 128, lr: float = 0.05) -> dict:
    """ì‹¤í—˜ 3: ì›ë³¸ + ìƒì„±í˜•(sd32)"""
    return run_experiment(
        experiment_name="generated",
        samples_per_class=samples,
        num_augment=0,
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        use_generated=True,
    )


# ==============================
# ë©”ì¸ ì‹¤í–‰(ì˜ˆì‹œ)
# ==============================

if __name__ == "__main__":
    print("ğŸš€ CIFAR-10 ë°ì´í„° ì¦ê°• ì‹¤í—˜")
    print("="*70)

    # ê³µì • ë¹„êµ ê¸°ë³¸ê°’(í•„ìš”ì‹œ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ì „ì²´ì— ë°˜ì˜)
    SAMPLES_PER_CLASS = 100
    EPOCHS = 100
    BATCH = 128
    LR = 0.05

    # ì‹¤í—˜ 1: Baseline (ì›ë³¸ 1,000ì¥)
    print("\n" + "="*70)
    print("ì‹¤í—˜ 1: Baseline")
    print("="*70)
    result1 = experiment_baseline(samples=SAMPLES_PER_CLASS, epochs=EPOCHS,
                                  batch_size=BATCH, lr=LR)

    # ì‹¤í—˜ 2: Traditional (ì›ë³¸ 1,000 + ì¦ê°• 1,000 = 2,000ì¥)
    print("\n" + "="*70)
    print("ì‹¤í—˜ 2: Traditional Augmentation")
    print("="*70)
    result2 = experiment_traditional(samples=SAMPLES_PER_CLASS, augment_ratio=1,
                                     epochs=EPOCHS, batch_size=BATCH, lr=LR)

    # ì‹¤í—˜ 3: Generated (ì›ë³¸ 1,000 + ìƒì„± 1,000 = 2,000ì¥)
    # í•„ìš” ì‹œ í™œì„±í™”
    # print("\n" + "="*70)
    # print("ì‹¤í—˜ 3: Generated Images")
    # print("="*70)
    # result3 = experiment_generated(samples=SAMPLES_PER_CLASS, epochs=EPOCHS,
    #                                batch_size=BATCH, lr=LR)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
    print("="*70)
    print(f"ì‹¤í—˜ 1 (Baseline):     {result1['best_test_accuracy']:.4f}")
    print(f"ì‹¤í—˜ 2 (Traditional):  {result2['best_test_accuracy']:.4f}")
    # print(f"ì‹¤í—˜ 3 (Generated):    {result3['best_test_accuracy']:.4f}")
    print("="*70)
